{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFH Group Separater\n",
    "This notebook is an example of separating the spatially resolved SFHs of a galaxy into groups. The wasserstein_distance in scipy is used to calculate the earth mover's distance.  \n",
    "In the same folder, there is another python script \"GroupSeparater.py\" with the same code, which can be more smoothly run in command line mode.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.wcs import WCS\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import wasserstein_distance\n",
    "from astropy.wcs.utils import pixel_to_skycoord,skycoord_to_pixel\n",
    "from astropy.visualization import wcsaxes,ZScaleInterval,ImageNormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Galaxy and the Number of Groups\n",
    "Here we specify the galaxy of our interest, and the target number of groups.  \n",
    "I choose number 122 galaxy in the list, and the group number is 4 in this example.  \n",
    "When using the script, you can run the command \"python GroupSeparater.py 122 4\"\n",
    "The galaxy name list is \"FinalSelMuseMask3.csv\".  \n",
    "There are some core collapse SNe in the list, whose SFHs are not calculated.  \n",
    "Please make sure you specified a SN Ia with a solved SFH cube here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=122\n",
    "groupSize=4\n",
    "uvals,vvals=np.arange(50),np.arange(50)\n",
    "FinalSelMuse=pd.read_csv('FinalSelMuseMask3.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emdKnn(sfhCube,massMap,stepper=100,coreNum=10):\n",
    "    groupMap=np.random.randint(coreNum,size=(sfhCube.shape[1],sfhCube.shape[2]))+1\n",
    "    groupMap[np.isnan(sfhCube.sum(axis=0))]=0\n",
    "    groupMap[sfhCube.sum(axis=0)<0.8]=0\n",
    "    groupMap[np.isnan(massMap)]=0\n",
    "    groupMap=groupMap*1.0\n",
    "    groupMap[groupMap==0]=np.nan\n",
    "    groupMapOld=groupMap.copy()\n",
    "    for indexer in range(stepper):\n",
    "        meanSFH=[]\n",
    "        massList=[]\n",
    "        for group in range(1,coreNum+1):\n",
    "            sfhCubeSel=sfhCube[:,groupMap==group]\n",
    "            massSel=massMap[groupMap==group]\n",
    "            if sfhCubeSel.shape[1]<=1:continue\n",
    "            sfhCubeAvg=np.sum(sfhCubeSel*massSel,axis=1)/np.sum(massSel)\n",
    "            meanSFH.append(sfhCubeAvg)\n",
    "            massList.append(np.sum(massSel))\n",
    "        coreNum=len(meanSFH)\n",
    "        for x in range(groupMap.shape[0]):\n",
    "            for y in range(groupMap.shape[1]):\n",
    "                if np.isnan(groupMap[x,y]):continue\n",
    "                emdList=[wasserstein_distance(uvals,vvals,meanSFH[j],sfhCube[:,x,y]) for j in range(0,coreNum)]\n",
    "                groupMap[x,y]=np.argmin(emdList)+1\n",
    "        print(indexer)\n",
    "        if np.average(groupMap[np.isnan(groupMap)==False]==groupMapOld[np.isnan(groupMapOld)==False])==1:break\n",
    "        else:groupMapOld=groupMap.copy()\n",
    "    return groupMap,meanSFH,massList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data\n",
    "The \"ArcName\" in the list are the file names of these host galaxy IFU data cube that can be used to search in ESO science archive.  \n",
    "In my pipeline, I use the data cube with $3\\times 3$ spatial binning, and the binned file name is changed from \"ADP---\" to \"CDP---\".  \n",
    "All the resampled spectra data are stored in \"../MuseObject/MuseResample/\" directory, please check the directory name when you are running the code.  \n",
    "All the SFH data are stored in \"../MuseSFH/dataOut/\" directory, please check the directory name when you are running the code.  \n",
    "In the .fits file read into the variable \"ppxfOut\", there are two HDUs.  \n",
    "The first HDU stores the fitting spectra from ppxf.  \n",
    "The second HDU stores the spatially resolved SFHs.  \n",
    "Both the HDU shapes are matched with the resampled IFU data cube.  \n",
    "Also, the SFHs have the shape (50,7), to match the stellar population with 50 age grids and 7 metallicity grids used in ppxf.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcName=FinalSelMuse['ArcName'][i]\n",
    "crcName=arcName.replace('ADP','CDP')\n",
    "fitsFile=fits.open('../MuseObject/MuseResample/'+crcName+'.fits')\n",
    "ppxfOut=fits.open('../MuseSFH/dataOut/'+str(i)+'_'+FinalSelMuse['SN Name'][i]+'.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pixel of SN\n",
    "Here, we identify the pixel closest to the SN coordinate.  \n",
    "The point spread function is also extracted here, and converted from arcsec to pixel length.  \n",
    "To notice, in the resampled data, one pixel corresponding to 0.6 arcsec.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcsselect=WCS(fitsFile[1])\n",
    "snCoord=SkyCoord(FinalSelMuse['SN RA'][i]*u.deg,FinalSelMuse['SN DEC'][i]*u.deg)\n",
    "minpos=skycoord_to_pixel(snCoord,wcsselect)\n",
    "minpos=(int(minpos[0]),int(minpos[1]))\n",
    "psfSig=fitsFile[0].header['SKY_RES']/0.6/2.355#0.6 here is the pixel size in arcsec for MUSE, 2.355 is the conversion between sigma and FWHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Map of Mass\n",
    "In ppxf, the fitting spectra are normalized to 1 solar mass of total initial stellar mass.  \n",
    "Here, we divide the observed spectra by the fitting spectra and pick up the median ratio, as the mass of the stars in the pixel.  \n",
    "I am not sure if the flux levels in MUSE are properly calibrated, but at least such a mass map can tell the relative mass within the galaxy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/user/chenxingzhuo/.conda/envs/tardis/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:908: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "/scratch/user/chenxingzhuo/.conda/envs/tardis/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in less\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "fitFlux=ppxfOut[0].data\n",
    "massMap=np.nanmedian(fitsFile[1].data,axis=0)/np.nanmedian(fitFlux,axis=0)\n",
    "massMap[massMap<0]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine the SFH data cube\n",
    "Here, we just ignore the metallicity and make the SFH into (50,1) shape.  \n",
    "Also, well.... we convolve the SFH on the spatial dimension with the observed PSF, this step will make the whole pipeline more stable.  \n",
    "By the way, without such a convolution, the SFH map looks quite noizy and cannot identify the psf shape, we suppose such a convolution can regularize the SFH results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/user/chenxingzhuo/.conda/envs/tardis/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in less\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "sfhCube=ppxfOut[1].data\n",
    "sfhCube=sfhCube.sum(axis=1)\n",
    "sfhCube[sfhCube<0]=0\n",
    "sfhCube[np.isnan(sfhCube)]=0\n",
    "sfhCube[:,np.isnan(massMap)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indexer in range(50):sfhCube[indexer]=gaussian_filter(sfhCube[indexer],sigma=psfSig,truncate=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Group Map Calculator\n",
    "The function is defined several cells above.  \n",
    "The maximum step is 100, adequate for most of the cases.  \n",
    "Finally all the data will be stored in a fits file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "groupMap,meanSFH,massList=emdKnn(sfhCube,massMap,coreNum=groupSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSFH=np.array(meanSFH)\n",
    "massList=np.array(massList)\n",
    "\n",
    "mapHdu=fits.PrimaryHDU(data=groupMap)\n",
    "mapHdu.header['Type']='Group Map'\n",
    "sfhHdu=fits.ImageHDU(data=meanSFH)\n",
    "sfhHdu.header['Type']='Mean SFH'\n",
    "masHdu=fits.ImageHDU(data=massList)\n",
    "masHdu.header['Type']='Mass List'\n",
    "mapFits=fits.HDUList([mapHdu,sfhHdu,masHdu])\n",
    "mapFits.writeto('GroupMap/'+str(i)+'_'+FinalSelMuse['SN Name'][i]+'_'+str(groupSize)+'.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
